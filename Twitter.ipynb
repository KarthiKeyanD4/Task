{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fSNFuOlevo1A"
      },
      "outputs": [],
      "source": [
        "# Packages for commmon functions\n",
        "import re\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Packages mostly used for vectorizing and lemmation\n",
        "import spacy\n",
        "\n",
        "# Packages for modelling\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting the english dictionary\n",
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "78_556rf3AtI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for preprossing where lemmatizing and stop words are removed\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    token_list = []\n",
        "    for token in doc:\n",
        "        if token.is_stop == False and token.lemma_.isalpha() == True: # it will filter the symbols and stopwords from the dictionary\n",
        "            token_list.append(token.lemma_)\n",
        "    return token_list"
      ],
      "metadata": {
        "id": "PSIPMW0mrnhl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize(text):\n",
        "  vector = TfidfVectorizer(tokenizer = preprocess) # using the preprocessing function as tokenizer in Tfid-Vectorize\n",
        "  X = vector.fit_transform(text).toarray()\n",
        "  return X"
      ],
      "metadata": {
        "id": "SKqy4z1R5NeK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usually, The given situation is regarding degree of profanity. We could consider the output to be binary i.e) 0 - No Racist comments, 1 - Racist Comment."
      ],
      "metadata": {
        "id": "u_BRS4MQmkKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the output is binary, We could go for Logistic Regression or SVM for modelling"
      ],
      "metadata": {
        "id": "LEbsw-x3BP7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_1(X,y):\n",
        "  model = LinearSVC(class_weight='balanced',C=0.01, penalty='l2', loss='squared_hinge',).fit(X, y)\n",
        "  y_pred = model.predict(X)\n",
        "  report = classification_report(y,y_pred)\n",
        "  return [report, y_pred]"
      ],
      "metadata": {
        "id": "Yruz_N-tjUBY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Example with a data set. "
      ],
      "metadata": {
        "id": "FsCUqEOsh1t1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"labeled_data.csv\")"
      ],
      "metadata": {
        "id": "pwOoXw5AP0ZV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = vectorize(df['tweet'])"
      ],
      "metadata": {
        "id": "pGhjIsmbP8S6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['class']"
      ],
      "metadata": {
        "id": "50lUKNkAQKdI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame(X)"
      ],
      "metadata": {
        "id": "Wmc-2u_oQNh8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = model_1(X,y)"
      ],
      "metadata": {
        "id": "IDzk3D3VQNkW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The summary of the model is \\n {G[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7e1RQzkR6ga",
        "outputId": "29adbe93-ffd5-4e06-90a8-4a21aa438c0f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The summary of the model is \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.53      0.47      0.50      1430\n",
            "           1       0.95      0.93      0.94     19190\n",
            "           2       0.82      0.90      0.85      4163\n",
            "\n",
            "    accuracy                           0.90     24783\n",
            "   macro avg       0.76      0.76      0.76     24783\n",
            "weighted avg       0.90      0.90      0.90     24783\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The first 5 prediction of y values is \\n {G[1][:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSf4T_uCf4aX",
        "outputId": "03012290-d7bd-4313-ba0b-e6e01be50254"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 5 prediction of y values is \n",
            " [2 1 1 1 1]\n"
          ]
        }
      ]
    }
  ]
}